{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROMPT RESULT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import plan_helper\n",
    "\n",
    "pred_dict = json.load(open('result/alfred/prompt20/roberta_penalty/valid_seen-plan_13.json', 'r'))\n",
    "num_plan = []\n",
    "for goal in pred_dict:\n",
    "    plans = pred_dict[goal]['plan']\n",
    "    num_plan.append(plan_helper.count_plans(plans))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "nBin = (max(num_plan)-min(num_plan)+1)\n",
    "counts, edges, bars = plt.hist(num_plan, bins=nBin)\n",
    "plt.bar_label(bars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "def preprocess(s):\n",
    "    # remove escape sequence\n",
    "    s = s.strip()\n",
    "    if \"\\n\" in s:\n",
    "        s = s.split(\"\\n\")[0]\n",
    "    elif \"\\b\" in s:\n",
    "        s = s.strip(\"\\b\")\n",
    "    # CounterTop -> Counter Top\n",
    "    if not any(_s.isupper() for _s in s):\n",
    "        # lower\n",
    "        return s.lower()\n",
    "    l = re.findall('[A-Z][^A-Z]*', s)\n",
    "    ls = []\n",
    "    left = s.split(l[0])[0]\n",
    "    for _l in l:\n",
    "        if len(_l) == 1:\n",
    "            left += _l\n",
    "        else:\n",
    "            _l = left+_l\n",
    "            ls.extend(_l.split())\n",
    "            left = ''\n",
    "    # lower\n",
    "    return ' '.join(ls).lower().replace('.', '')\n",
    "\n",
    "goal2plan = json.load(open('result/alfred/prompt20/roberta_penalty/valid_seen-plan_8.json', 'r'))\n",
    "goal2sentences = json.load(open('result/alfred/roberta/valid_seen-sentence@20.json', 'r'))\n",
    "\n",
    "# (Acc, Recall, F1, goal)\n",
    "success = []\n",
    "fail = []\n",
    "kAcc = 0\n",
    "\n",
    "for ep in os.listdir('data/alfred_data/json_2.1.0/valid_seen'):\n",
    "    for trial in os.listdir(os.path.join('data/alfred_data/json_2.1.0/valid_seen', ep)):\n",
    "        traj_data = json.load(open(os.path.join('data/alfred_data/json_2.1.0/valid_seen', ep, trial, 'traj_data.json')))\n",
    "        anns = [ann['task_desc'] for ann in traj_data['turk_annotations']['anns']]\n",
    "        gt = [action['discrete_action'] for action in traj_data['plan']['high_pddl'] if action['discrete_action']['action'] not in ['GotoLocation', 'NoOp']]\n",
    "        for goal in anns:\n",
    "            try:\n",
    "                preds = goal2plan[goal]['plan']\n",
    "            except:\n",
    "                continue\n",
    "            pred = preds[0]\n",
    "            tp = 0\n",
    "            for action in pred:\n",
    "                temp = []\n",
    "                for arg in action['args']:\n",
    "                    temp.append(arg.lower())\n",
    "                action['args'] = temp\n",
    "                if action in gt:\n",
    "                    tp += 1\n",
    "            acc = tp/len(pred)\n",
    "            recall = tp/len(gt)\n",
    "            try:\n",
    "                f1 = 2/(1/acc+1/recall)\n",
    "            except ZeroDivisionError:\n",
    "                f1 = 0\n",
    "            if acc == 1 and recall == 1:\n",
    "                success.append((acc, recall, f1, goal))\n",
    "            else:\n",
    "                fail.append((acc, recall, f1, goal))\n",
    "            result = []\n",
    "            for j, pred in enumerate(preds):\n",
    "                if len(pred) != len(gt):\n",
    "                    result.append(False)\n",
    "                    continue\n",
    "                for i, action in enumerate(pred):\n",
    "                    temp = []\n",
    "                    for arg in action['args']:\n",
    "                        temp.append(arg.lower())\n",
    "                    action['args'] = temp\n",
    "                    if gt[i] != action:\n",
    "                        result.append(False)\n",
    "                        break\n",
    "                if len(result) != j+1:\n",
    "                    result.append(True)\n",
    "            if any(result):\n",
    "                kAcc += 1\n",
    "                # print(gt)\n",
    "                # print(preds)\n",
    "print('@kAcc: %.2f'%(kAcc/40))\n",
    "print(kAcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "success_xs = np.array([1]*len(success))\n",
    "success_ys = np.array([goal2plan[s[-1]]['prompt_logp'] for s in success]) \n",
    "\n",
    "fail_xs = []\n",
    "fail_ys = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[0])\n",
    "    fail_ys.append(goal2plan[ex[-1]]['prompt_logp'])\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "acc_plot = plt.subplot(1, 3, 1)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('gpt logp')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[1])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('gpt logp')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[2])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('gpt logp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "success_xs = np.array([1]*len(success))\n",
    "success_ys = np.array([np.mean(np.log(np.array(goal2plan[s[-1]]['trans_cossim']))) for s in success]) \n",
    "\n",
    "fail_xs = []\n",
    "fail_ys = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[0])\n",
    "    fail_ys.append(np.mean(np.log(np.array(goal2plan[ex[-1]]['trans_cossim']))))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "acc_plot = plt.subplot(1, 3, 1)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('avg(log(cos_sim))')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[1])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('avg(log(cos_sim))')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[2])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('avg(log(cos_sim))')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "success_xs = np.array([1]*len(success))\n",
    "success_ys = np.array([min(goal2plan[s[-1]]['trans_cossim']) for s in success]) \n",
    "\n",
    "fail_xs = []\n",
    "fail_ys = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[0])\n",
    "    fail_ys.append(min(goal2plan[ex[-1]]['trans_cossim']))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "acc_plot = plt.subplot(1, 3, 1)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('min(cos_sim)')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[1])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('min(cos_sim)')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[2])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('min(cos_sim)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "# 100의 표준편차 점수\n",
    "\n",
    "success_xs = np.array([])\n",
    "success_ys = np.array([])\n",
    "for s in success:\n",
    "    success_xs = np.append(success_xs, 1)\n",
    "    scores = np.array(goal2sentences[s[-1]]['score'])\n",
    "    success_ys = np.append(success_ys, np.std(scores))\n",
    "\n",
    "fail_xs = []\n",
    "fail_ys = []\n",
    "for ex in fail:\n",
    "    fail_xs = np.append(fail_xs, ex[0])\n",
    "    scores = np.array(goal2sentences[ex[-1]]['score'])\n",
    "    fail_ys = np.append(fail_ys, np.std(scores))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "acc_plot = plt.subplot(1, 3, 1)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('std cos_sim @k')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[1])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('std cos_sim @k')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[2])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('std cos_sim @k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "# 100의 표준편차 점수\n",
    "\n",
    "success_xs = np.array([])\n",
    "success_ys = np.array([])\n",
    "for s in success:\n",
    "    success_xs = np.append(success_xs, 1)\n",
    "    scores = np.array(goal2sentences[s[-1]]['score'])\n",
    "    z = (1-np.mean(scores))/np.std(scores)\n",
    "    success_ys = np.append(success_ys, (1-norm.cdf(z)))\n",
    "\n",
    "fail_xs = []\n",
    "fail_ys = []\n",
    "for ex in fail:\n",
    "    fail_xs = np.append(fail_xs, ex[0])\n",
    "    scores = np.array(goal2sentences[ex[-1]]['score'])\n",
    "    z = (1-np.mean(scores))/np.std(scores)\n",
    "    fail_ys = np.append(fail_ys, 1-norm.cdf(z))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "acc_plot = plt.subplot(1, 3, 1)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('ACC')\n",
    "plt.xlabel('normal dist P(1 < cos_sim @k)')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[1])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('normal dist P(1 < cos_sim @k)')\n",
    "\n",
    "fail_xs = []\n",
    "for ex in fail:\n",
    "    fail_xs.append(ex[2])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(success_ys, success_xs, 'ro')\n",
    "plt.plot(fail_ys, fail_xs, 'bo')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('normal dist P(1 < cos_sim @k)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('valid seen')\n",
    "k = [1, 5, 10, 15, 20, 50, 100]\n",
    "acc = [57.87, 75.59, 79.68, 82.16, 83.34, 87.86, 90.09]\n",
    "film_full = 77.52\n",
    "film = 67.20\n",
    "hier1 = 86.01\n",
    "hier2 = 87.56\n",
    "\n",
    "plt.ylim(50, 95)\n",
    "plt.plot(k, acc, 'bo', label='RoBERTa')\n",
    "plt.xticks(k)\n",
    "for x, y in zip(k, acc):\n",
    "    plt.annotate(y, (x, y), textcoords='offset points', xytext=(0, 10), ha='center')\n",
    "plt.xlabel('k (# of samples)')\n",
    "plt.ylabel('@k acc')\n",
    "plt.hlines(film_full, min(k), max(k), label='FILM(low+high)', colors='coral', linestyles='dashed')\n",
    "plt.hlines(film, min(k), max(k), label='FILM(high only)', colors='coral')\n",
    "plt.hlines(hier1, min(k), max(k), label='Hierarchical(prev)', colors='lightgreen', linestyles='dashed')\n",
    "plt.hlines(hier2, min(k), max(k), label='Hierarchical(updated)', colors='green', linestyles='dashed')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('valid unseen')\n",
    "k = [1, 5, 10, 15, 20, 50, 100]\n",
    "acc = [54.41, 66.67, 70.88, 72.46, 73.91, 78.13, 79.45]\n",
    "film_full = 73.34\n",
    "film = 66.45\n",
    "hier1 = 72.29\n",
    "hier2 = 85.02\n",
    "\n",
    "plt.ylim(50, 95)\n",
    "plt.plot(k, acc, 'bo', label='RoBERTa')\n",
    "plt.xticks(k)\n",
    "for x, y in zip(k, acc):\n",
    "    plt.annotate(y, (x, y), textcoords='offset points', xytext=(0, 10), ha='center')\n",
    "plt.xlabel('k (# of samples)')\n",
    "plt.ylabel('@k acc')\n",
    "plt.hlines(film_full, min(k), max(k), label='FILM(low+high)', colors='coral', linestyles='dashed')\n",
    "plt.hlines(film, min(k), max(k), label='FILM(high only)', colors='coral')\n",
    "plt.hlines(hier1, min(k), max(k), label='Hierarchical(prev)', colors='lightgreen', linestyles='dashed')\n",
    "plt.hlines(hier2, min(k), max(k), label='Hierarchical(updated)', colors='green', linestyles='dashed')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from utils import plan_helper\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from utils import pre_cal_param_acc\n",
    "\n",
    "OPENABLE_CLASS_LIST = ['Fridge', 'Cabinet', 'Microwave', 'Drawer', 'Safe']\n",
    "\n",
    "data = json.load(open('result/alfred/roberta/valid_seen-sentence@100.json', 'r'))\n",
    "# data = json.load(open('data/film/val_seen_full-plan.json', 'r'))\n",
    "suc, cnt = 0, 0\n",
    "\n",
    "def is_gtPlan_in_prompt(goal, sim_goals):\n",
    "    train_plan_dict = json.load(open('data/train_tripletPlan.json', 'r'))\n",
    "    for ep in os.listdir('data/alfred_data/json_2.1.0/valid_seen'):\n",
    "        for trial in os.listdir(os.path.join('data/alfred_data/json_2.1.0/valid_seen', ep)):\n",
    "            traj_data = json.load(open(os.path.join('data/alfred_data/json_2.1.0/valid_seen', ep, trial, 'traj_data.json'), 'r'))\n",
    "            anns = [ann['task_desc'] for ann in traj_data['turk_annotations']['anns']]\n",
    "            if goal not in anns:\n",
    "                continue\n",
    "            gt_plan = plan_helper.make_triplet_plan(traj_data)\n",
    "    \n",
    "    for action in gt_plan:\n",
    "        if action[0] in ['PickupObject', 'SliceObject'] and action[2] in OPENABLE_CLASS_LIST:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_film_right(goal, plan):\n",
    "    for ep in os.listdir('data/alfred_data/json_2.1.0/valid_seen'):\n",
    "        for trial in os.listdir(os.path.join('data/alfred_data/json_2.1.0/valid_seen', ep)):\n",
    "            traj_data = json.load(open(os.path.join('data/alfred_data/json_2.1.0/valid_seen', ep, trial, 'traj_data.json'), 'r'))\n",
    "            anns = [pre_cal_param_acc.film_preprocess(ann['task_desc']) for ann in traj_data['turk_annotations']['anns']]\n",
    "            if goal not in anns:\n",
    "                continue\n",
    "            gt_plan = plan_helper.make_triplet_plan(traj_data)\n",
    "    # ignore type of knife and lamp\n",
    "    toggle = False\n",
    "    slice = False\n",
    "    for action in gt_plan:\n",
    "        if action[0] == 'SliceObject':\n",
    "            slice = True\n",
    "        if action[0] == 'ToggleObject':\n",
    "            toggle = True\n",
    "\n",
    "    if len(plan) != len(gt_plan):\n",
    "        return False\n",
    "    \n",
    "    for i in range(len(gt_plan)):\n",
    "        # action 다름\n",
    "        if gt_plan[i][0] != plan[i]['action']:\n",
    "            return False\n",
    "        # put action\n",
    "        if gt_plan[i][0] == 'PutObject':\n",
    "            if slice and 'knife' in gt_plan[i][1].lower() and 'knife' in plan[i]['args'][0].lower():\n",
    "                continue\n",
    "            if gt_plan[i][2].lower() != plan[i][\"args\"][1].lower():\n",
    "                return False\n",
    "        # pick action or slice action\n",
    "        elif gt_plan[i][0] in ['PickupObject', 'SliceObject']:\n",
    "            # if not (gt_plan[i][2] == '' or gt_plan[i][2] not in OPENABLE_CLASS_LIST):\n",
    "            #     return False\n",
    "            # if slice and 'knife' in gt_plan[i][1].lower() and 'knife' in plan[i]['args'][0].lower() and \\\n",
    "            #     (gt_plan[i][2] == '' or gt_plan[i][2] not in OPENABLE_CLASS_LIST):\n",
    "            #     continue\n",
    "            # if not slice and (gt_plan[i][1] != plan[i]['args'][0] or \\\n",
    "            #     (gt_plan[i][2] != '' and gt_plan[i][2] in OPENABLE_CLASS_LIST)):\n",
    "            #     return False\n",
    "            if slice and 'knife' in gt_plan[i][1].lower() and 'knife' in plan[i]['args'][0].lower():\n",
    "                continue\n",
    "            if not slice and gt_plan[i][1] != plan[i]['args'][0]:\n",
    "                return False\n",
    "        # toggle action\n",
    "        elif gt_plan[i][0] == 'ToggleObject':\n",
    "            if 'lamp' in gt_plan[i][1].lower() and 'lamp' in plan[i]['args'][0].lower():\n",
    "                continue\n",
    "        else:\n",
    "            if gt_plan[i][1] != plan[i]['args'][0]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "pool = Pool(16)\n",
    "for retr in pool.starmap(is_gtPlan_in_prompt, tqdm(data.items())):\n",
    "    cnt += 1\n",
    "    if retr:\n",
    "        suc += 1\n",
    "pool.close()\n",
    "pool.join()\n",
    "###FOR DEBUG\n",
    "# for goal, sim_goals in tqdm(data.items()):\n",
    "#     is_film_right(goal, sim_goals)\n",
    "        \n",
    "print('%d / %d: %.2f'%(suc, cnt, suc/cnt*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace 써보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동으로 기본 모델과 preprocessing을 사용해서 inference한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline() \n",
    "# task='', model='',  -- huggingface hub에 있는대로 가져와야 함. ex) openai/whisper-large\n",
    "# task specific parameters는 task API 확인. ex) transformers.[taskname]Pipeline.call()의 파라미터\n",
    "result = generator(input_data) # 여러개면 list of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0fbdb265074cfab05ea1c28f424e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a71189b98140bda71c01e40b7ce166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c6e1f36e7545149be1d44e7b00e085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7540080c82c4ab2977f7cd8b729c6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b579f29f04cc4e4fadf26615cd3e61c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e054023e7249f58b1690a7b3ec50f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/language-planner/lib/python3.7/site-packages/transformers/generation/utils.py:1212: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  \"You have modified the pretrained model configuration to control generation. This is a\"\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/user/anaconda3/envs/language-planner/lib/python3.7/site-packages/transformers/generation/utils.py:1302: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'New way to solve the problem is to give your children a new school that will be similar to yours. The first step is to set up a new school that will teach English and you must send him to a similar school in a different country. The'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(model='gpt2', device=0)\n",
    "print(generator('New way to solve the problem is'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지정해서 사용하기\n",
    "pipeline = tokenizer + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained() # 모델 이름\n",
    "encoded_input = tokenizer('') # input, padding, truncation, return_tensors='pt', ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoding method\n",
    "* greedy search (default)\n",
    "* contrastive search - non-repetitive, long\n",
    "* beam-search decoding - 전체 sequence를 참조해서 가장 prob 높은 것을 고른다, num beams는 keep하는 hypothesis의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8884a84d4f34990a59ebca5aaece207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9259ddecc62e4b669d47fc4fcdbd884d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cada5d3d314487ca885a3daddb9a652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d341cb2048f44db8917ba88dc1f9df97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a659ea3daec41278fe13db4656c63ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14395cc79b814223a968b18f5b669593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Correct this to standard English:\\n slice WineBottle\\nThis will give you a list of all the WineBottles you have in your inventory. If you have more than one WineBottle in your inventory, you will get a list of all the WineBottles you have in your inventory. If you']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = 'gpt2-xl' # gpt2-xl\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer('Correct this to standard English:\\n slice WineBottle\\n', return_tensors='pt')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "outputs = model.generate(**inputs, num_beams=5, max_new_tokens=50)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앗... 여러개 할 수 있었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from utils import config\n",
    "\n",
    "openai.api_key = config.OPENAI['api_key']\n",
    "openai.organization = config.OPENAI['organization']\n",
    "\n",
    "prompt = [\"Correct this to standard English:\\n\\n%s\\n\"%('abs'), \"Correct this to standard English:\\n\\n%s\\n\"%('do something'), \"Correct this to standard English:\\n\\n%s\\n\"%('can you help me out?')]\n",
    "\n",
    "response = openai.Completion.create(\n",
    "                model = 'text-davinci-003',\n",
    "                prompt = prompt,\n",
    "                temperature = 0,\n",
    "                logprobs=1,\n",
    "                n = 1,\n",
    "                max_tokens = 60,\n",
    "                stop = None\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nAbs', '\\nDo something.', '\\nCan you help me?']\n"
     ]
    }
   ],
   "source": [
    "print([c.text for c in response.choices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('language-planner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30c9be03abade3e0206d1fafbc0eb5216ba825e070628d9092f0b83804e3a265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
